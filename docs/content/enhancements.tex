%----------------------------------------------------------------------------
\chapter{Enhancements} \label{enhancements}
%----------------------------------------------------------------------------

This chapter describes a few alternatives to improve the dependability of the sample application that can happen either by implementing additional features or making architectural changes to the system.

%----------------------------------------------------------------------------
\section{Introduction}
%----------------------------------------------------------------------------

With the application and the initial measurements being ready, the next task is to attempt to make the dependability of the application better. In the next sections, the possible methods and architectural layers are explored, where the enhancements are feasible and the design aspects of two concrete approaches -- Kafka and a custom logic called Heartbeats -- are described (see Section \ref{enhancements-design}). Later, the implementational details and the related build pipeline modifications of the preceding enhancement alternatives are discussed (see Section \ref{enhancements-impl}).

%----------------------------------------------------------------------------
\section{Design} \label{enhancements-design}
%----------------------------------------------------------------------------

%\begin{itemize}
%	\item possibilities to enhance dependability - in which layers of the deployment (infr, K8s definition, application, using 3rd party technologies)
%	\item CI/CD pipeline changes -  new steps
%\end{itemize}

The robustness of the system can be enhanced in different layers. Some options are presented below:

\paragraph{Kubernetes Infrastructure layer} The Kubernetes infrastructure layer is the fundamental tier of the whole system. Even a little configuration change can have a huge impact on the behavior of the applications. For instance, to tackle Pod lifecycle related failure anomalies, the Kubernetes Scheduler could be extended to introduce application specific fine tuning.

\paragraph{Kubernetes Deployment layer} This layer affects how the application is deployed and run on the Kubernetes cluster. The dependability of the system can be improved with the right selection and configuration of Kubernetes objects. For example, all the component Pods could be replicated (not just the worker) or scaled with using a Horizontal Pod Autoscaler to eliminate single-point-of-failures from the system.

\paragraph{Service layer} In the service layer third-party tools can be used to outsource or to make better some feature-sets of the application. A distributed database or messaging solution could improve the availability and robustness of the system.

\paragraph{Application layer} To achieve application level progress, the source code and the design of the backend and worker components should be analyzed in order to discover weak spots. Distributed software development best-practices can help achieving a higher level of dependability in the system.

%----------------------------------------------------------------------------
\subsection{Kafka}
%----------------------------------------------------------------------------

Apache Kafka is an open-source distributed event streaming platform that can be used for high-performance data pipelines, streaming analytics and data integration \cite{Kafka}. It acts as a scalable, fault tolerant publish-subscribe messaging system ideal for performance critical applications. Further details about Kafka can be found in Section \ref{background-kafka}.

The baseline measurements revealed that injecting Pod Failure and Pod Kill anomalies into the system can cause considerable decrease in both availability and the number of successfully finished tasks executed by the worker components (see Section \ref{baseline-results}). One reason could be that the current message broker acts as a single point of failure. If it stops due to and error, no submitted tasks can be sent to the workers to process and no finished tasks can be sent to the backend component.

In this project, Kafka could be used to replace ActiveMQ to provide a robust, more fault-tolerant messaging solution for the application. Kafka topics can be used to facilitate the forwarding of task submissions and results in the system. The backend and worker components can both act as producers and consumers of the topics. As a Kafka cluster operates with at least three message brokers, one could hope for better availability and job success ratio.

%----------------------------------------------------------------------------
\subsection{Heartbeats}
%----------------------------------------------------------------------------

Heartbeats is a custom enhancement option in the application to provide reliable task execution.

In the original implementation of the system, when a worker instance stops during the calculation of a task, the task is lost and its result remains empty in the database. This means that Pod Failure and Pod Kill fault profiles can greatly affect the number of successful task executions, as already seen in Section \ref{baseline-results} covering the baseline measurements.

One could add additional features to the application to mitigate these fault scenarios, by introducing another communication channel between the backend and worker components to keep track of task executions. If the backend detects that a task is lost during execution, it should resend the task to the worker components. Enter Heartbeats.

%----------------------------------------------------------------------------
\section{Implementation} \label{enhancements-impl}
%----------------------------------------------------------------------------

This section presents the implementation details of the two enhancement proposals mentioned above.

%----------------------------------------------------------------------------
\subsection{Kafka}
%----------------------------------------------------------------------------

%\begin{itemize}
%	\item deploy kafka
%	\item adapt backend and worker
%	\item adapt needed worker ratio metric
%	\item use kafka exporter
%	\item integrate JMX into kafka?
%\end{itemize}

There are official or community managed Kafka charts available, however, to be able to have full control over the tool, Kafka is deployed to the system with the usage of a custom helm chart. The default recommended way to run a Kafka cluster is to run 3 Kafka brokers along with a ZooKeeper cluster. ZooKeeper \cite{ZooKeeper} is an open source, centralized service for maintaining configuration information, naming, providing distributed synchronization. It supports the Kafka brokers in order to be able to discover each other.

The Horizontal Pod Autoscaler that manages the replica count of the worker components constantly observers a metric which the scaling is based upon (see Section \ref{impl-hpa}). This metric includes the number of messages in the message queue. The Docker image used for running ActiveMQ supported exposing Prometheus compatible metrics, yet that is not the case with Kafka. In order to get metrics from the Kafka cluster a custom exporter should be used \cite{KafkaExporter}. That leads to the modification of the metric used for autoscaling, instead of the usage of the ActiveMQ queue size, the following metric is used:

%TODO explain this metric better

\vspace{0.5cm}
\begin{minipage}{\linewidth}
	\begin{lstlisting}[caption={Metric for the number of unconsumed messages in Kafka}, label={lst:kafka-consumerlag-metric}]
	kafka_consumergroup_lag_sum{consumergroup="worker",topic="jobWorkerTopic"}\end{lstlisting}
\end{minipage}

To adapt the backend and worker to use Kafka instead of ActiveMQ as a messaging system, similar modifications were needed in both components using the \texttt{org.springframework.kafka:spring-kafka} library. The related source code van be found under the \texttt{messaging/kafka} package in the components in the thesis repository \cite{ThesisRepo}.

%----------------------------------------------------------------------------
\subsection{Heartbeats}
%----------------------------------------------------------------------------

%\begin{itemize}
%	\item adapt backend and worker
%	\item scheduled tasks
%\end{itemize}

The basic idea of Heartbeats is to constantly track which tasks are executed in worker components.

When a worker starts the calculations for a task, it continuously sends heartbeat messages to the backend every few seconds providing the identifier of the task. The backend component maintains a map about the state of each task storing the timestamp of the last received heartbeat message for each task. It periodically checks the heartbeat timestamps of unfinished tasks and resubmits those with timestamps older than a minute. To prevent the map getting too big, the backend removes the information about successfully finished jobs from the data structure.

To achieve periodic operations both in the backend and the worker components, the Spring annotation \texttt{@Scheduled} is used.


%----------------------------------------------------------------------------
\subsection{Build Pipeline Modifications} \label{cicd-modifications}
%----------------------------------------------------------------------------

The build pipeline presented in Section \ref{cicd} introduces new stages and modifies existing ones to support the optional enabling of enhancements.

\paragraph{Set up Enhancements (\texttt{ENHNC - set up})} This stage configures and installs the helm chart for Kafka onto the Kubernetes cluster. The execution of Kafka deployment is controlled by the pipeline parameter \texttt{UseKafka}.

\paragraph{Deploy Application (\texttt{APP - deploy})} The stage is extended with passing parameters to the application helm chart that control which enhancement options to use.




