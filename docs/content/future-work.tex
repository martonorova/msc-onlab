%----------------------------------------------------------------------------
\chapter{Future Work} \label{future-work}
%----------------------------------------------------------------------------

This chapter endeavors to collect some possible directions for future developments concerning the implemented and integrated systems used during this thesis project.

%----------------------------------------------------------------------------
\section{Test Framework}
%----------------------------------------------------------------------------

The test framework involves a lot of functionality and configuration options that for the best results and experience require a level of maturity that was not the scope of this thesis project. There are several parts of the test framework that can be extended or fine-tuned.

\paragraph{Extended Load Generation Parameterization} Although the number of simulated users to generate load to the sample application can be controlled with parameters, the frequency of the requests sent to the backend component and their payload are still hard-coded into the framework (see Section \ref{test-impl-load-generation}). In order to be able to conduct deeper analyses, it is indispensable to have the option to control these parameters as well.

\paragraph{Chaos Experiment fine-tuning} The fault profiles described in Section \ref{test-impl-fault-profiles} demonstrate well the possible fault injection scenarios, however, the configured values that set the strength of each chaos experiment only serve as starting point for more thorough measurements. These values need to be fine-tuned for specific use-cases and should be modified based on the testing requirements. As the baseline measurements discovered, there are already some chaos experiments -- like the Stress CPU or Stress Memory -- that do not have much effect on the sample application. Their configurations should be re-evaluated and set in a way to cause more severe interference.

\paragraph{Cross-cloud Measurements} Cloud system developers have the possibility to choose from a lot of cloud providers to host their infrastructure. Furthermore, it is not rare that companies decide to deploy their applications collaborating with multiple cloud providers to achieve a higher level of reliability or to satisfy various conformance requirements. This leads to the fact that the testing framework created here in this thesis project should also support executing measurements in multiple cloud environments starting with the most popular ones next AWS like Microsoft Azure or Google Compute Cloud. 

\paragraph{Pipeline Decomposition} The Jenkins pipeline introduced in Section \ref{cicd} is responsible for automating the whole process of measurements from the creation of the infrastructure to saving the results. Currently, all the tasks and steps for achieving this are grouped together in a single Jenkins pipeline, which brings up maintainability issues and a steep learning curve for those who do not have much experiment with these tools. Therefore this pipeline should be decomposed into multiple smaller ones, each having a more focused set of goals and one that orchestrates the entire process. This would result in fewer parameters for each Jenkins job and better modularity concerning the pipeline logic.

\paragraph{Visualization Extensions} The test framework is currently capable of displaying the state of the system and the value of the dependability metrics in near real-time during measurements with the help of Prometheus and Grafana. However, the present configuration does not allow the users of the framework to track the fault injection and the state of the chaos experiments on an easy to understand interface. Future works should include the integration of visualizing the collected metrics and the information available about the chaos experiments on one comprehensive dashboard in order to facilitate more thorough investigations.

%----------------------------------------------------------------------------
\section{Enhancements}
%----------------------------------------------------------------------------

During this thesis work, only two enhancements were implemented that attempted to improve the dependability of the sample application (see Chapter \ref{enhancements}). These two were enough to display the possible power of the framework and to reveal some weaknesses in the sample application. It is not difficult see, that an increasing number of integrated enhancement options can enable a better understanding of the system that needs to be improved dependability-wise. The following paragraphs introduce some enhancement ideas to be implemented in the future, but one should consider other possible alternatives as well.

\paragraph{High Availability Mode} The architecture of the sample application (see in Section \ref{sample-app-arch}) reveals multiple single point of failure components in the system. One of these problems is already addressed with the Kafka enhancements, however the high availability of the backend and the database is not implemented yet. Future works should make an effort to create a separate enhancement case for each of these two components to run them with multiple instances. The number of replicas could be dynamically determined based on the system workload with the help of Horizontal Pod Autoscalers.

\paragraph{Kafka Improvements} The measurement results revealed that integrating Kafka into the sample system with the basic configurations does not improve the dependability metrics of the sample application (see Chapter \ref{evaluation}). Forthcoming developments should address this issue and set up a Kafka cluster that can reliably replace the current messaging subsystem in the sample application. 

\paragraph{Kubernetes Configurations} Dependability improvements could be achieved with fine-tuning the Kubernetes configuration of the system. For example, scheduling the components that communicate with each other on the same physical nodes can reduce the impact of network related anomalies in the system. Of course, this kind of grouping of components is vulnerable to physical node failures, therefore, replicating each component on separate machines is critical to maintain the reliability of the system. Apart from this example, future works should consider other possible Kubernetes configuration improvements to make applications more robust.

%taints, affinity to schedule communicating components on the same node (need to be replicated!)

%\begin{itemize}
%	\item database in HA mode (currently single instance, spof)
%	\item HPA enhancement for backend
%	\item improve Kafka configurations to make it usable
%	\item try to create more enhancements
%\end{itemize}